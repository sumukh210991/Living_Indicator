{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        import numpy as np\n",
    "# np.set_printoptions(threshold='nan')\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "# display plots in this notebook\n",
    "# %matplotlib inline\n",
    "import caffe\n",
    "import sys\n",
    "caffe_root = '/home/student/Documents/PSPNet'  # this file should be run from {caffe_root}/examples (otherwise change this line)\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "caffe.set_mode_cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_def = '/home/student/Documents/caffe/models/bvlc_alexnet/deploy.prototxt'\n",
    "model_weights = '/home/student/Documents/caffe/models/bvlc_alexnet/bvlc_alexnet.caffemodel'\n",
    "\n",
    "net = caffe.Net(model_def,      # defines the structure of the model\n",
    "                model_weights,  # contains the trained weights\n",
    "                caffe.TEST)  \n",
    "\n",
    "mu = np.load('/home/student/Documents/caffe/python/caffe/imagenet/ilsvrc_2012_mean.npy')\n",
    "# mu = np.load(caffe_root + 'python/caffe/imagenet/ilsvrc_2012_mean.npy')\n",
    "mu = mu.mean(1).mean(1)  # average over pixels to obtain the mean (BGR) pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "\n",
    "transformer.set_transpose('data', (2,0,1))  # move image channels to outermost dimension\n",
    "transformer.set_mean('data', mu)            # subtract the dataset-mean value in each channel\n",
    "transformer.set_raw_scale('data', 255)      # rescale from [0, 1] to [0, 255]\n",
    "transformer.set_channel_swap('data', (2,1,0))  # swap channels from RGB to BGR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = caffe.io.load_image('/home/student/Documents/Living_Indicator/img/file44.png')\n",
    "# image = caffe.io.load_image('/home/student/Desktop/hourglass.jpg')\n",
    "    transformed_image = transformer.preprocess('data', image)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.blobs['data'].data[...] = transformed_image\n",
    "output = net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for layer_name, param in net.params.iteritems():\n",
    "    # print layer_name + '\\t' + str(param[0].data.shape)+ ' ' + str(param[1].data.shape)\n",
    "    print layer_name + '\\t' + str(param[0].data.shape)+ ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for layer_name, blob in net.blobs.iteritems():\n",
    "    print layer_name + '\\t' + str(blob.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aa = net.blobs['fc7'].data[:,:]\n",
    "print(aa.shape)\n",
    "# plt.imshow(aa.reshape(64,64))\n",
    "print(aa[aa != 0].shape)\n",
    "print(np.max(aa))\n",
    "print(np.argmax(aa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = aa\n",
    "temp = np.vstack((temp, aa))\n",
    "temp = np.vstack((temp, aa))\n",
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat1 = np.loadtxt(\"/home/student/Sumukh/Living_Indicator/localized_color_hist.csv\", delimiter = ',')\n",
    "exmp1 = feat1[0,:]\n",
    "length = feat1.shape[0]\n",
    "feat2 = feat1.reshape(length*64, 8)\n",
    "exmp2 = feat2[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "y = np.row_stack( ([3.984893309, 3.9596817709, 3.9660237719, 3.9751477788],\n",
    "                 [3.980425611, 3.9552164138, 3.9625861326, 3.9715395937],\n",
    "                 [3.9844938166, 3.9576173088, 3.9663763831, 3.9764159225],\n",
    "                 [3.9861526974, 3.957728888, 3.967391121, 3.9783991173]\n",
    "                 ) )\n",
    "\n",
    "x = np.array([4,5,7,10]) \n",
    " \n",
    "\n",
    "print(y)\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.set_ylabel(\"Mean Sqyared Error (MSE)\")\n",
    "ax1.set_xlabel(\"Max Depth of random Forest\")\n",
    "ax1.set_title(\"MSE vs Max depth of Random forest for Different N_Estimators (Augmented Color HOI features)\")\n",
    "\n",
    "ax1.plot(x, y[0,:], label=200)\n",
    "ax1.plot(x, y[1,:], label=300)\n",
    "ax1.plot(x, y[2,:], label=500)\n",
    "ax1.plot(x, y[3,:], label=600)\n",
    "\n",
    "ax1.legend(loc=2, title = \"No. of Estimators\")\n",
    "\n",
    "plt.savefig('/home/student/Sumukh/forfiles/Results_Augmented/Random_forest_random_aug_raw.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "y = np.row_stack( ([5.0996346821, 5.2170849369, 5.3689698362, 5.5245386849],\n",
    "                 [5.2787464284, 5.0291352985, 5.1739803957, 5.3791911523],\n",
    "                 [5.2592349068, 5.239994606, 5.205441993, 5.1211037473]\n",
    "                 ) )\n",
    "my_xticks = [\"(1000, 500) \\n (1000, 700, 200) \\n (1000, 700, 500,100)\",\n",
    "             \"(1000, 200) \\n (1000, 500, 200) \\n (1000, 500, 300,100)\",\n",
    "             \"(500, 200) \\n (1000, 500, 100) \\n (1000, 500, 200,100)\",\n",
    "             \"(500, 50) \\n (1000, 300, 100) \\n (1000,500, 200, 50)\"]\n",
    "x = np.array([1, 2, 3, 4]) \n",
    "#x = [\"(1000, 500)\",\"(1000, 200)\",\"(500, 200)\",\"(500, 50)\"]\n",
    "print(y)\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.xticks(x, my_xticks)\n",
    "ax.set_ylabel(\"Mean Sqyared Error (MSE)\")\n",
    "ax.set_xlabel(\"Number of layers in neiral network\")\n",
    "ax.set_title(\"MSE vs Number of layers in neural network for different number of units (Augmented Color HOI features)\")\n",
    "\n",
    "\n",
    "ax.plot(x, y[0,:], label=\"2 hidden layers\")\n",
    "ax.plot(x, y[1,:], label=\"3 hidden layers\")\n",
    "ax.plot(x, y[2,:], label=\"4 hidden layers\")\n",
    "#ax1.plot(x, y[3,:], label=600)\n",
    "\n",
    "ax.legend(loc=2, title = \"No. of Estimators\")\n",
    "\n",
    "#plt.show('/home/student/Sumukh/forfiles/Results_Augmented/Random_forest_random_aug_raw.png')\n",
    "plt.savefig('/home/student/Sumukh/forfiles/Results_Augmented/Neural_network_random_aug_raw.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainx = np.loadtxt(\"/home/student/Sumukh/Feature_files/raw_cnn_feat/raw_cnn_feat_0_130.csv\", delimiter = ',')\n",
    "\n",
    "print(trainx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "def get_Living_Index(res):\n",
    "    zestimate = res['zestimate_amount']\n",
    "    property_size = res['property_size']\n",
    "    home_size = res['home_size']\n",
    "\n",
    "    zestimate = zestimate.fillna(np.median(zestimate[np.isnan(zestimate) == False]))\n",
    "    property_size = property_size.fillna(np.median(property_size[np.isnan(property_size) == False]))\n",
    "    home_size = home_size.fillna(np.median(home_size[np.isnan(home_size) == False]))\n",
    "\n",
    "    zestimate = np.array(zestimate)\n",
    "    property_size = np.array(property_size)\n",
    "    home_size = np.array(home_size)\n",
    "\n",
    "    builtin_ratio = property_size / home_size\n",
    "\n",
    "\n",
    "    # Normalizing zestimate and builtin_ratio for PCA\n",
    "    zestimate1 = np.array([0 + ((i - min(zestimate)) * 1) / (max(zestimate) - min(zestimate)) for i in zestimate])\n",
    "    builtin_ratio1 = np.array(\n",
    "        [0 + ((i - min(builtin_ratio)) * 1) / (max(builtin_ratio) - min(builtin_ratio)) for i in builtin_ratio])\n",
    "\n",
    "    original_features = np.vstack((zestimate1, builtin_ratio1)).T\n",
    "\n",
    "    arr_orig_features = np.array(original_features)\n",
    "\n",
    "    score_pca = PCA(n_components=1)\n",
    "    score = score_pca.fit_transform(arr_orig_features)\n",
    "\n",
    "    for i in range(0, len(score)):\n",
    "        if (score[i] > 0.054): # threshold for zillow_id = 1000000.0, property_size[i] / home_size[i] = 18\n",
    "            score[i] = 0.054\n",
    "\n",
    "    finalscore = np.array([0 + ((i - min(score)) * 10) / (max(score) - min(score)) for i in score])\n",
    "\n",
    "    return finalscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epsilon = 1e-4\n",
    "numiter = 10000\n",
    "alpha = 0.0000008\n",
    "#theta = np.zeros(trainx.shape[1])\n",
    "#theta = theta.reshape(368640,1)\n",
    "theta = np.loadtxt(\"/home/student/Sumukh/Feature_files/terrain_cnn_feat/Theta_terrain_long/terrain_theta_long_5500_5600.csv\", delimiter = ',')\n",
    "theta = theta.reshape(368640,1)\n",
    "m = len(trainy)\n",
    "for _ in range(1,numiter):\n",
    "    pred = np.dot(trainx, theta).reshape(m, 1)\n",
    "    temp = np.dot(np.transpose(pred - trainy), (trainx))\n",
    "    temp = temp.reshape(368640,1)\n",
    "    temp *= (alpha / m)\n",
    "    theta -= temp\n",
    "    val = np.sum((np.dot(trainx,theta) - trainy)) / m\n",
    "    print(val)\n",
    "    if(np.abs(val) < epsilon):\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"/home/student/Sumukh/Feature_files/terrain_cnn_feat/Theta_terrain_long/terrain_theta_long_5600_5654.csv\", theta, delimiter = ',', newline = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainx = np.loadtxt(\"/home/student/Sumukh/Feature_files/terrain_cnn_feat/terrain_cnn_feat_5600_5654_.csv\", delimiter = ',')\n",
    "trainx.resize(54, 4096*90)\n",
    "print(trainx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = pd.read_csv('/home/student/Sumukh/Living_Indicator/resultset_12000')\n",
    "temp_y = get_Living_Index(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''trainy = np.empty(0)\n",
    "for i in temp_y[0:130]:\n",
    "    trainy = np.append(trainy, np.repeat(i, 90))\n",
    "print(trainy.shape) '''\n",
    "trainy = temp_y[5600:5654]\n",
    "print(trainy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# np.set_printoptions(threshold='nan')\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "# display plots in this notebook\n",
    "# %matplotlib inline\n",
    "import sys\n",
    "caffe_root = '/home/student/Documents/PSPNet/'  # this file should be run from {caffe_root}/examples (otherwise change this line)\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "\n",
    "import caffe\n",
    "caffe.set_mode_cpu()\n",
    "\n",
    "filenames = []\n",
    "for i in range(0,len(res)):\n",
    "    name = \"/home/student/Documents/Living_Indicator/img/file\"+str(i)+\".png\"\n",
    "    filenames.append(name)\n",
    "\n",
    "model_def = '/home/student/Documents/caffe/models/bvlc_alexnet/deploy.prototxt'\n",
    "model_weights = '/home/student/Documents/caffe/models/bvlc_alexnet/bvlc_alexnet.caffemodel'\n",
    "\n",
    "net = caffe.Net(model_def,  # defines the structure of the model\n",
    "                model_weights,  # contains the trained weights\n",
    "                caffe.TEST)\n",
    "\n",
    "mu = np.load('/home/student/Documents/caffe/python/caffe/imagenet/ilsvrc_2012_mean.npy')\n",
    "mu = mu.mean(1).mean(1)  # average over pixels to obtain the mean (BGR) pixel values\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "\n",
    "transformer.set_transpose('data', (2, 0, 1))  # move image channels to outermost dimension\n",
    "#transformer.set_mean('data', mu)  # subtract the dataset-mean value in each channel\n",
    "transformer.set_raw_scale('data', 255)  # rescale from [0, 1] to [0, 255]\n",
    "#transformer.set_channel_swap('data', (2, 1, 0))  # swap channels from RGB to BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "feat = np.empty(0)\n",
    "\n",
    "for i in range(4683, 5654):\n",
    "    image = caffe.io.load_image(filenames[i])\n",
    "    transformed_image = transformer.preprocess('data', image)\n",
    "\n",
    "    net.blobs['data'].data[...] = transformed_image\n",
    "    output = net.forward()\n",
    "\n",
    "    temp = net.blobs['fc7'].data[:, :]\n",
    "\n",
    "    if (count == 0):\n",
    "        feat = temp\n",
    "    else:\n",
    "        feat = np.vstack((feat, temp))\n",
    "\n",
    "    count = count + 1\n",
    "    print(count)\n",
    "\n",
    "    del temp\n",
    "\n",
    "print(feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51390, 4096)\n"
     ]
    }
   ],
   "source": [
    "feat = np.loadtxt(\"/home/student/Sumukh/Feature_files/raw_cnn_feat/raw_cnn_feat_test_data.csv\", delimiter = ',')\n",
    "print(feat.shape)\n",
    "#feat = feat.reshape(feat.shape[0] / 90, 368640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat = feat.reshape(feat.shape[0] / 90, 368640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n",
      "(571,)\n",
      "MSE = 1.4609196436\n",
      "r2_score = 0.664061499713\n",
      "min_err = 2.67841537068e-05\n",
      "max_err = 23.7752611749\n",
      "median_err = 0.441145635327\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "trainy = np.empty(0)\n",
    "testy = temp_y[5083:5654]\n",
    "    \n",
    "print(trainy.shape)\n",
    "\n",
    "theta = np.loadtxt(\"/home/student/Sumukh/Feature_files/raw_cnn_feat/Theta_vals_long/raw_theta_long_5583_5654.csv\", delimiter = ',')\n",
    "#print(trainx.shape)\n",
    "pred = np.dot(feat, theta)\n",
    "print(pred.shape)\n",
    "\n",
    "pred = pred.reshape(feat.shape[0],1)\n",
    "MSE = mean_squared_error(testy, pred)\n",
    "print(\"MSE = \" + str(MSE))\n",
    "r2score = r2_score(testy, pred)\n",
    "print(\"r2_score = \" + str(r2score))\n",
    "sq_err = np.array([x**2 for x in (pred - testy)])\n",
    "sq_err = sq_err.flatten()\n",
    "min_err = min(sq_err)\n",
    "print(\"min_err = \" + str(min_err))\n",
    "max_err = max(sq_err)\n",
    "print(\"max_err = \" + str(max_err))\n",
    "median_err = np.median(sq_err)\n",
    "print(\"median_err = \" + str(median_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456\n",
      "2.67841537068e-05\n",
      "(571,)\n",
      "[334 329 325   7 263  86  26 374  93  55  46 392  83 370   8 360   0 307\n",
      " 116 318 388 320  78  91  19]\n",
      "16.5081925968\n",
      "5090\n",
      "[ 5.93697248]\n",
      "[ 10.]\n"
     ]
    }
   ],
   "source": [
    "print(np.argmin(sq_err))\n",
    "print(sq_err[456])\n",
    "print(sq_err.shape)\n",
    "print(sq_err.argsort()[::-1][:25])\n",
    "print(sq_err[7])\n",
    "print(5083+7)\n",
    "print(pred[7])\n",
    "print(testy[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "res = pd.read_csv('/home/student/Sumukh/Living_Indicator/resultset_12000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nh+EgSer4f+DXygkHliTzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f034ea0bfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# display plots in this notebook\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "fname = \"/home/student/Sumukh/Living_Indicator/img/file1835.png\"\n",
    "\n",
    "img = cv2.imread(fname)\n",
    "#plt.imshow(img)\n",
    "plt.hist(img.ravel(),256,[0,256])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f034e6a1f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SaveLoc = \"/home/student/Desktop/test1.png\"\n",
    "plt.savefig(SaveLoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990293.0\n",
      "3000.0\n",
      "3200.0\n",
      "45.532142\n",
      "-122.696258\n",
      "2.0\n",
      "1.0\n",
      "53846309\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "print(res['zestimate_amount'][5417])\n",
    "print(res['property_size'][5417])\n",
    "print(res['home_size'][5417])\n",
    "print(res['latitude'][5417])\n",
    "print(res['longitude'][5417])\n",
    "print(res['bedrooms'][5417])\n",
    "print(res['bathrooms'][5417])\n",
    "print(res['zillow_id'][5417])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import os\n",
    "def GetStreet(Address, SaveLoc):\n",
    "    meta = \"https://maps.googleapis.com/maps/api/streetview/metadata?\"\n",
    "    base = \"https://maps.googleapis.com/maps/api/streetview?size=1200x800&\"\n",
    "    params = {\"location\": Address,\n",
    "              \"width\": \"600\",\n",
    "              \"height\": \"400\",\n",
    "              \"key\": \"AIzaSyC7-APuKb-aknoKymJdflh2jTC91HBe8rY\",\n",
    "              \"heading\":\"100.5\",\n",
    "              \"fov\": \"100\",\n",
    "              \"pitch\": \"0\",\n",
    "              \"heading\": \"1\"}\n",
    "    metaurl = meta + urllib.urlencode(params)\n",
    "    MyUrl = base + urllib.urlencode(params)\n",
    "    #fi = SaveLoc + r\"\\myfile.png\"\n",
    "    status = requests.get(metaurl)\n",
    "    if (\"ZERO_RESULTS\" in str(status.content)):\n",
    "        print(\"TRUE\")\n",
    "    else:\n",
    "        print(\"FALSE\")\n",
    "    print(status.content)\n",
    "    print(status)\n",
    "    res = urllib.urlretrieve(MyUrl, SaveLoc)\n",
    "    print(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FALSE\n",
      "{\n",
      "   \"copyright\" : \"© Google, Inc.\",\n",
      "   \"date\" : \"2017-09\",\n",
      "   \"location\" : {\n",
      "      \"lat\" : 45.39923052455444,\n",
      "      \"lng\" : -122.7231011243746\n",
      "   },\n",
      "   \"pano_id\" : \"XFgzMnmRI5cTt7BFCm61Jg\",\n",
      "   \"status\" : \"OK\"\n",
      "}\n",
      "\n",
      "<Response [200]>\n",
      "('/home/student/Desktop/test1.png', <httplib.HTTPMessage instance at 0x7f034f453200>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/student/Desktop/test1.png',\n",
       " <httplib.HTTPMessage instance at 0x7f034f453200>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Address = \"17484-Bryant-Rd-Lake-Oswego-OR-97035\"\n",
    "SaveLoc = \"/home/student/Desktop/test1.png\"\n",
    "GetStreet(Address, SaveLoc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
